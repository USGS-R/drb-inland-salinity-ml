---
title: "DRB salinity data availability"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: html_document
---

## Records summary  
  


```{r,echo=FALSE,message=FALSE,warning=FALSE}

##------------ WQP ------------##

# Load filtered WQP data
data_subset <- tar_read(p2_wqp_salinity_data)

# Return Cl sites
Cl_sites <- data_subset %>%
  filter(param=="Chloride") %>%
  summarize(Site = unique(MonitoringLocationIdentifier))

# Load WQP data subsets for specific conductance 
SC_data <- tar_read(p2_wqp_SC_data) %>%
  mutate(site_no = if_else(grepl("USGS",MonitoringLocationIdentifier),substr(MonitoringLocationIdentifier,6,100),MonitoringLocationIdentifier))

# Return SC sites
SC_sites <- SC_data %>%
  summarize(Site = unique(MonitoringLocationIdentifier))

# Calculate percent of data subset representing censored data
Cl_censored <- data_subset %>% 
  filter(param=="Chloride") %>%
  mutate(Censored = ifelse(ResultDetectionConditionText=="NA","N","Y")) %>%
  group_by(Censored) %>%
  summarize(n=n()) %>%
  summarize(n[which(Censored=="Y")]/n[which(Censored=="N")]*100) %>%
  as.numeric() %>%
  round(2)

SC_censored <- SC_data %>% 
  mutate(Censored = ifelse(is.na(ResultDetectionConditionText),"N","Y")) %>%
  group_by(Censored) %>%
  summarize(n=n()) %>%
  summarize(n[which(Censored=="Y")]/n[which(Censored=="N")]*100) %>%
  as.numeric() %>%
  round(2)

# Calculate percent of data labeled as preliminary
Cl_prelim <- data_subset %>% 
  filter(param=="Chloride") %>%
  mutate(Prelim = ifelse(ResultStatusIdentifier=="Preliminary","Y","N")) %>%
  group_by(Prelim) %>%
  summarize(n=n()) %>%
  summarize(n[which(Prelim=="Y")]/n[which(Prelim=="N")]*100) %>%
  as.numeric() %>%
  round(2)

SC_prelim <- SC_data %>%
  mutate(Prelim = ifelse(ResultStatusIdentifier=="Preliminary","Y","N")) %>%
  group_by(Prelim) %>%
  summarize(n=n()) %>%
  summarize(n[which(Prelim=="Y")]/n[which(Prelim=="N")]*100) %>%
  as.numeric() %>%
  round(2)

##------------ NWIS ------------##

# Load NWIS daily SC sites and data
SC_sites_nwis <- tar_read(p1_nwis_sites)
SC_data_nwis <- tar_read(p1_daily_data)


# Load full site list:
site_list_path <- tar_read(p2_site_list_nontidal_csv)
site_list <- read_csv(site_list_path,show_col_types = FALSE)
site_tally <- read_csv(tar_read(p3_sitelist_summary_csv),show_col_types = FALSE)
unique_wqp_lat_lon <- SC_data %>% distinct(LatitudeMeasure,LongitudeMeasure) %>% summarize(n_sites=n()) 

```
  
### 1. Harmonized WQP dataset
  
#### Input dataset  
The harmonized multiscale surface water quality dataset for the Delaware River Basin (Shoda et al. 2019) contains data for multiple water quality constituents that pertain to inland salinity. The harmonized dataset was created from data originally downloaded from the [Water Quality Portal](https://www.waterqualitydata.us/).

#### Data processing steps   
We filtered the full dataset to include only measurements related to surface water salinity (`param_group = Salinity` or, for chloride and sodium, `param_group = Majors` & `param = Chloride|Sodium`). From this data subset we further excluded samples for which the original data entry referenced "conductivity" rather than "specific conductance" and no further information regarding the temperature basis was reported. Sediment samples, samples from tidal streams, and samples from ditch locations were excluded from the processed data (`ActivityMediaName != "Sediment"`; `MonitoringLocationTypeName` does not contain the word "tidal"; `MonitoringLocationTypeName != "Stream: Ditch"`), as were any samples assigned to specific hydrologic event codes that were not of interest to our study (`HydrologicEvent = "Spill"|"Volcanic action"`). Finally, we were interested in raw measurements of inland salinity so samples with parameter codes denoting "min" or "max" were excluded from the filtered dataset (e.g. `param = "Specific conductance, field, max`).    
  
The full dataset includes many data QA/QC flags, including flags for undesired analytical methods, measurements with missing, ambiguous, or undesired units, and flags for duplicate measurements, among others. To process the data we followed the recommendations of the dataset creators with regard to these data quality flags and subset the data to only include records deemed suitable for further analysis (`final=="retain"`). Note that the retained records include samples tagged as `ResultStatusIdentifier = Preliminary` within the Water Quality Portal (Chloride: `r paste0(Cl_prelim,"%")`; SpConductance = `r paste0(SC_prelim,"%")`). Next, in the full dataset, censored values (e.g., where the measurement is reported as "less than" or "greater than" the limit deemed reliable for reporting) are retained if a detection level was also reported. In those cases, the measurement value is assumed equal to the quantitation limit given, which is often common practice and the dataset creators cite as USGS-style, even though these substitution methods can bias summary statistics. Therefore a very small proportion of the filtered dataset for the inland salinity project represents censored measurements (e.g.,Chloride: `r paste0(Cl_censored,"%")`; Specific conductance: `r paste0(SC_censored,"%")`).  

The original coordinate reference system used for the lat/lon coordinates was not retained in the harmonized dataset. To create a list of unique sites, we searched the Water Quality Portal (`dataRetrieval::whatWQPsites()`) for sites within the target HUC8 watersheds, and matched the returned CRS to the harmonized dataset according to the site ID (`MonitoringLocationIdentifier`).


```{r r-table, echo=FALSE}

# Print salinity records overview table
data_subset %>% 
  filter(CharacteristicName!="Conductivity",!grepl("min|max", param,ignore.case = TRUE)) %>%
  group_by(param_group,CharacteristicName,param) %>% 
  summarize(n_records = n(),n_sites = length(unique(MonitoringLocationIdentifier)),.groups="keep") %>%
  kable()

```

**Specific conductance**  

The sites represented by these different salinity parameters often overlap. For example, `r length(intersect(Cl_sites$Site,SC_sites$Site))` sites have both chloride and specific conductance records. We will most likely begin model development by focusing on specific conductance. The data processing steps outlined above leaves us with `r length(SC_data$resultVal2)` observations distributed across `r length(unique(SC_data$MonitoringLocationIdentifier))` unique site id's (note that some site id's appear to share geospatial coordinates; there are `r unique_wqp_lat_lon$n_sites` unique lat/lon locations within the harmonized dataset).    

Most sites have relatively few specific conductance observations:

```{r,echo=FALSE,fig.height=3.8,fig.width=5}

SC_data %>% 
  group_by(MonitoringLocationIdentifier) %>% 
  summarize(n=n()) %>%
  ggplot() + 
  stat_ecdf(aes(x=n),geom = "step",color="darkblue",size=0.8) + 
  scale_x_log10() + 
  xlab("Number of observations per site") + ylab("Cumulative frequency") +
  theme_bw() 

```

<br>  

The number of specific conductance records, as well as the number of different sites represented, picks up after ~2000.   

```{r,echo=FALSE}

SC_data %>% 
  group_by(ActivityStartDate) %>% 
  summarize(n_sites = length(unique(MonitoringLocationIdentifier))) %>% 
  mutate(Year = year(ActivityStartDate),doy = yday(ActivityStartDate)) %>% 
  ggplot() +
  geom_tile(aes(x=doy,y=Year,fill=n_sites)) + 
  scale_fill_gradient(low = "#eff3ff", high = "#08519c",trans="log",breaks= c(1,5,50)) + 
  theme_bw() + 
  theme(axis.line = element_line(color='black'),
    plot.background = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank())

```

<br>

Zoom in on the sites with the most total samples:  

```{r,echo=FALSE}

top_sites <- SC_data %>% 
  group_by(MonitoringLocationIdentifier) %>% 
  summarize(n_records = n()) %>% 
  arrange(desc(n_records)) %>%
  slice(1:50) 
  
SC_data %>% 
  filter(MonitoringLocationIdentifier %in% top_sites$MonitoringLocationIdentifier) %>%
  mutate(Year = year(ActivityStartDate),doy = yday(ActivityStartDate)) %>%
  group_by(MonitoringLocationIdentifier,Year) %>%
  summarize(n_records_per_yr = n(),.groups="keep") %>%
  mutate(Site = factor(MonitoringLocationIdentifier,levels=top_sites$MonitoringLocationIdentifier)) %>%
  ggplot() +
  geom_tile(aes(x=Year,y= reorder(Site, desc(Site)),fill=n_records_per_yr)) + 
  scale_fill_gradient(trans="log",breaks= c(1,10,50,150)) + 
  coord_cartesian(xlim=c(1908,2020)) + labs(y = "Site") +
  theme_bw() + 
  theme(axis.line = element_line(color='black'),
    plot.background = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major = element_blank())

```

<br>  

To what extent is there seasonal bias in the discrete samples?

```{r,echo=FALSE}

samples_by_month <- SC_data %>% 
  mutate(Year = year(ActivityStartDate),
         Month = month(ActivityStartDate),
         doy = yday(ActivityStartDate)) %>%
  group_by(Month) %>% summarize(n=n()) 

samples_by_month_topsites <- SC_data %>% 
  filter(MonitoringLocationIdentifier %in% top_sites$MonitoringLocationIdentifier) %>%
  mutate(Year = year(ActivityStartDate),
         Month = month(ActivityStartDate),
         doy = yday(ActivityStartDate)) %>%
  group_by(Month) %>% summarize(n=n())


  ggplot() + geom_bar(data = samples_by_month,aes(x=as.factor(Month),y=n,fill="all sites"),stat="identity") +
    geom_bar(data = samples_by_month_topsites,aes(x=as.factor(Month),y=n,fill="top-50 sites"),stat="identity") +
    scale_fill_manual(values = c("darkgray","cornflowerblue"))+
    labs(x="Month",y="# discrete SC observations across the DRB") + 
    theme_bw() + 
    theme(legend.title = element_blank())

```

<br>  

### 2. NWIS continuous data  

#### Data processing steps  
NWIS sites with specific conductance data were identified by querying NWIS for sites within the Delaware River Basin with data matching the parameter codes "00095","90095","00094", or "90096". Note that other USGS parameter codes have been used to record specific conductance which were not used for this project (e.g. "90094","99974","99978","99982","00402") but may be relevant for extending this work to other basins beyond the DRB. 

The spatial extent of the DRB for this project encompasses the Upper and Lower Delaware basins including the following HUC08 watersheds (https://water.usgs.gov/GIS/huc_name.html): 02040101, 02040102, 02040103, 02040104, 02040105, 02040106, 02040201, 02040202, 02040203, 02040204, 02040205, 02040206, and 02040207. The two New Jersey Coastal HUC08 watersheds within the Delaware subregion (0204) were excluded (HUC08 = 02040301 and 02040302).  


<br>  

### Specific conductance site locations  

Combining the harmonized WQP dataset with daily data from NWIS (which includes data from NGWOS high-frequency stations), here is a map of site locations with specific conductance data (n = `r site_tally$n_unique_latlon` unique lat/lon locations):  

```{r,echo=FALSE}

site_list_map <- map_SC_sites(site_list_path)
site_list_map

```

<br>  

## Data citations  

Shoda, M.E., Murphy, J.C., Falcone, J.A., and Duris, J.W., 2019, Multisource surface-water-quality data and U.S. Geological Survey streamgage match for the Delaware River Basin: U.S. Geological Survey data release, [https://doi.org/10.5066/P9PX8LZO](https://doi.org/10.5066/P9PX8LZO).

<br>  